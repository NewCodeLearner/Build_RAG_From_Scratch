{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n6hhDs37vPx"
      },
      "source": [
        "# Create and run a local RAG pipeline from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BD1JsIh7vP3"
      },
      "source": [
        "The goal of this notebook is to build a RAG (Retrieval Augmented Generation) pipeline from scratch and have it run on a local GPU.\n",
        "\n",
        "Specifically, we'd like to be able to open a PDF file, ask questions (queries) of it and have them answered by a Large Language Model (LLM).\n",
        "\n",
        "There are frameworks that replicate this kind of workflow, including LlamaIndex and LangChain, however, the goal of building from scratch is to be able to inspect and customize all the parts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jio4g4__7vP4"
      },
      "source": [
        "# What is RAG?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_GP3cea7vP4"
      },
      "source": [
        "RAG stands for Retrieval Augmented Generation.\n",
        "\n",
        "It was introduced in the paper  [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.](https://arxiv.org/abs/2005.11401)\n",
        "\n",
        "Each step can be roughly broken down to:\n",
        "\n",
        "Retrieval - Seeking relevant information from a source given a query. For example, getting relevant passages of Wikipedia text from a database given a question.    \n",
        "Augmented - Using the relevant retrieved information to modify an input to a generative model (e.g. an LLM).    \n",
        "Generation - Generating an output given an input. For example, in the case of an LLM, generating a passage of text given an input prompt.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HimGI7BZ7vP5"
      },
      "source": [
        "# Why RAG?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxJcIz-g7vP5"
      },
      "source": [
        "The main goal of RAG is to improve the generation outputs of LLMs.\n",
        "\n",
        "Two Primary improvements can be seen as:\n",
        "1.Preventing Hallucinations: LLMs are incredible but they are prone to potential hallucinations as in generating something that looks correct but it isn't.RAG pipelines can help LLMs generate more factual outputs by providing them with the factual (retrived) inputs. and even if the generated answer from RAG pipeline doesn't seem correct, because of retrieval, you also have access to the sources where it came from.\n",
        "2.Work with custom data : Many base LLMs are trained with internet scale text data. This means they have great ability to model language, however they often lack specific knowldge. RAG systems can provide LLMs with domain specific data such as medical information or company documentation and thus customized their outputs to suit specific use cases.\n",
        "\n",
        "RAG can also be a much quicker solution to implement than fine-tuning an LLM on specific data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oP6iZOFK7vP6"
      },
      "source": [
        "# What kind of problems can RAG be used for?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79Y7O2DK7vP6"
      },
      "source": [
        "RAG can help anywhere there is a specific set of information that an LLM may not have in its training data (e.g. anything not publicly accessible on the internet).\n",
        "\n",
        "For example you could use RAG for:\n",
        "\n",
        "Customer support Q&A chat - By treating your existing customer support documentation as a resource, when a customer asks a question, you could have a system retrieve relevant documentation snippets and then have an LLM craft those snippets into an answer. Think of this as a \"chatbot for your documentation\". Klarna, a large financial company, uses a system like this to save $40M per year on customer support costs.\n",
        "Email chain analysis - Let's say you're an insurance company with long threads of emails between customers and insurance agents. Instead of searching through each individual email, you could retrieve relevant passages and have an LLM create strucutred outputs of insurance claims.\n",
        "Company internal documentation chat - If you've worked at a large company, you know how hard it can be to get an answer sometimes. Why not let a RAG system index your company information and have an LLM answer questions you may have? The benefit of RAG is that you will have references to resources to learn more if the LLM answer doesn't suffice.\n",
        "Textbook Q&A - Let's say you're studying for your exams and constantly flicking through a large textbook looking for answers to your quesitons. RAG can help provide answers as well as references to learn more.\n",
        "All of these have the common theme of retrieving relevant resources and then presenting them in an understandable way using an LLM.\n",
        "\n",
        "From this angle, you can consider an LLM a calculator for words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huiZvGcH7vP6"
      },
      "source": [
        "# Why local?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl5h3LGf7vP7"
      },
      "source": [
        "Privacy, speed, cost.\n",
        "\n",
        "Running locally means you use your own hardware.\n",
        "\n",
        "From a privacy standpoint, this means you don't have send potentially sensitive data to an API.\n",
        "\n",
        "From a speed standpoint, it means you won't necessarily have to wait for an API queue or downtime, if your hardware is running, the pipeline can run.\n",
        "\n",
        "And from a cost standpoint, running on your own hardware often has a heavier starting cost but little to no costs after that.\n",
        "\n",
        "Performance wise, LLM APIs may still perform better than an open-source model running locally on general tasks but there are more and more examples appearing of smaller, focused models outperforming larger models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j7fmV4a7vP7"
      },
      "source": [
        "# What we're going to build"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zwL-sEI7vP7"
      },
      "source": [
        "We are going to build RAG pipeline which enables us to chat with a PDF document.\n",
        "\n",
        "We will write the code toL\n",
        "1.Open a PDF document\n",
        "2.Format the text of the PDF ready for an embedding model(this process is known as text splitting/chunking)\n",
        "3.Embed all of the chunks of text in the pdf and turn them into numerical representation which we can store for later.\n",
        "4.Build a retrival system that uses vector search to find relevant chunks of the text based on a query.\n",
        "5.Create a prompt that incorporates the retrieved pieces of text.\n",
        "6.Generate an answer to a query on passages from the textbook.\n",
        "\n",
        "The above steps can be broken down into two major sections:\n",
        "1. Document preprocessing/embedding creation ( Step 1-3)\n",
        "2. Search and answer(steps 4-6)\n",
        "\n",
        "It's similar to the workflow outlined on the NVIDIA blog which details a local RAG pipeline. https://developer.nvidia.com/blog/rag-101-demystifying-retrieval-augmented-generation-pipelines/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements and setup"
      ],
      "metadata": {
        "id": "Egl8-rT89sja"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Thlq90W67vP8",
        "outputId": "a4a398d3-04f6-4ec9-8363-620bf7c736f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Running in Google Colab, installing requirements.\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.25.1\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.26.5)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.45.0\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.7.2.post1.tar.gz (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.5.1+cu121)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn) (0.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.2.post1-cp310-cp310-linux_x86_64.whl size=190160474 sha256=0b454d9e650bfc437cc71335080172a5d05f51eab355636c9d5b7321fec7318e\n",
            "  Stored in directory: /root/.cache/pip/wheels/da/ec/5b/b2c37a8e4f755ad82492a822463bca0817f0e0e11de874b550\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.7.2.post1\n"
          ]
        }
      ],
      "source": [
        "# Perform Google Colab installs (if running in Google Colab)\n",
        "import os\n",
        "\n",
        "if \"COLAB_GPU\" in os.environ:\n",
        "    print(\"[INFO] Running in Google Colab, installing requirements.\")\n",
        "    !pip install -U torch # requires torch 2.1.1+ (for efficient sdpa implementation)\n",
        "    !pip install PyMuPDF # for reading PDFs with Python\n",
        "    !pip install tqdm # for progress bars\n",
        "    !pip install sentence-transformers # for embedding models\n",
        "    !pip install accelerate # for quantization model loading\n",
        "    !pip install bitsandbytes # for quantizing models (less storage space)\n",
        "    !pip install flash-attn --no-build-isolation # for faster attention mechanism = faster LLM inference"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Document/Text Processing and Embedding Creation\n",
        "\n",
        "Ingredients:\n",
        "\n",
        "1.   PDF document of choice\n",
        "2.   Embedding mode of choice\n",
        "\n",
        "Steps:\n",
        "\n",
        "Import PDF document.\n",
        "\n",
        "1.   Process text for embedding (e.g. split into chunks fo sentences)\n",
        "2.   Embed text chunks with embedding model.\n",
        "3.   Save embeddings to file for later use(embeddings will store on file for many years or until you lose your hard drive)\n"
      ],
      "metadata": {
        "id": "SD_ATOkJ-LOF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Import PDF Document**\n",
        "\n",
        "This will work with many other kinds of documents.\n",
        "\n",
        "However, we'll start with PDF since many people have PDFs.\n",
        "\n",
        "But just keep in mind, text files, email chains, support documentation, articles and more can also work.\n",
        "\n",
        "There are several libraries to open PDFs with Python but I found that PyMuPDF works quite well in many cases.\n",
        "\n",
        "First we'll download the PDF if it doesn't exist."
      ],
      "metadata": {
        "id": "4xcbEWnX-bVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download PDF file\n",
        "import os\n",
        "import requests\n",
        "\n",
        "# Get PDF document\n",
        "pdf_path = \"human-nutrition-text.pdf\"\n",
        "\n",
        "# Download PDF if it doesn't already exist\n",
        "if not os.path.exists(pdf_path):\n",
        "  print(\"File doesn't exist, downloading...\")\n",
        "\n",
        "  # The URL of the PDF you want to download\n",
        "  url = \"https://pressbooks.oer.hawaii.edu/humannutrition2/open/download?type=pdf\"\n",
        "\n",
        "  # The local filename to save the downloaded file\n",
        "  filename = pdf_path\n",
        "\n",
        "  # Send a GET request to the URL\n",
        "  response = requests.get(url)\n",
        "\n",
        "  # Check if the request was successful\n",
        "  if response.status_code == 200:\n",
        "      # Open a file in binary write mode and save the content to it\n",
        "      with open(filename, \"wb\") as file:\n",
        "          file.write(response.content)\n",
        "      print(f\"The file has been downloaded and saved as {filename}\")\n",
        "  else:\n",
        "      print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
        "else:\n",
        "  print(f\"File {pdf_path} exists.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xXmZLAiAEFw",
        "outputId": "1c4d644e-2dfe-46b0-a099-a41f0194a268"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File doesn't exist, downloading...\n",
            "The file has been downloaded and saved as human-nutrition-text.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can import the pages of our PDF to text by first defining the PDF path and then opening and reading it with PyMuPDF (import fitz).\n",
        "\n",
        "We'll write a small helper function to preprocess the text as it gets read. Note that not all text will be read in the same so keep this in mind for when you prepare your text.\n",
        "\n",
        "We'll save each page to a dictionary and then append that dictionary to a list for ease of use later."
      ],
      "metadata": {
        "id": "-tNj-FE7f-JC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Requires !pip install PyMuPDF, see: https://github.com/pymupdf/pymupdf\n",
        "import fitz # (pymupdf, found this is better than pypdf for our use case, note: licence is AGPL-3.0, keep that in mind if you want to use any code commercially)\n",
        "from tqdm.auto import tqdm # for progress bars, requires !pip install tqdm\n",
        "\n",
        "def text_formatter(text: str) -> str:\n",
        "    \"\"\"Performs minor formatting on text.\"\"\"\n",
        "    cleaned_text = text.replace(\"\\n\", \" \").strip() # note: this might be different for each doc (best to experiment)\n",
        "\n",
        "    # Other potential text formatting functions can go here\n",
        "    return cleaned_text\n",
        "\n",
        "# Open PDF and get lines/pages\n",
        "# Note: this only focuses on text, rather than images/figures etc\n",
        "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Opens a PDF file, reads its text content page by page, and collects statistics.\n",
        "\n",
        "    Parameters:\n",
        "        pdf_path (str): The file path to the PDF document to be opened and read.\n",
        "\n",
        "    Returns:\n",
        "        list[dict]: A list of dictionaries, each containing the page number\n",
        "        (adjusted), character count, word count, sentence count, token count, and the extracted text\n",
        "        for each page.\n",
        "    \"\"\"\n",
        "    doc = fitz.open(pdf_path)  # open a document\n",
        "    pages_and_texts = []\n",
        "    for page_number, page in tqdm(enumerate(doc)):  # iterate the document pages\n",
        "        text = page.get_text()  # get plain text encoded as UTF-8\n",
        "        text = text_formatter(text)\n",
        "        pages_and_texts.append({\"page_number\": page_number - 41,  # adjust page numbers since our PDF starts on page 42\n",
        "                                \"page_char_count\": len(text),\n",
        "                                \"page_word_count\": len(text.split(\" \")),\n",
        "                                \"page_sentence_count_raw\": len(text.split(\". \")),\n",
        "                                \"page_token_count\": len(text) / 4,  # 1 token = ~4 chars, see: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\n",
        "                                \"text\": text})\n",
        "    return pages_and_texts\n",
        "\n",
        "pages_and_texts = open_and_read_pdf(pdf_path=pdf_path)\n",
        "pages_and_texts[:2]"
      ],
      "metadata": {
        "id": "XRT-dtemgdl8",
        "outputId": "36c97667-ef20-478f-bd82-1a01bd42dcd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267,
          "referenced_widgets": [
            "d41ef90950b249b4b81a76c2ac4d80c8",
            "692c600764514cfeb3aae1209197cc28",
            "158a0b121a63462ba8831bd583e8c36d",
            "34dec64fd23642e2aceb15c647bccbe3",
            "86a37dd502ab461daa16393a39e11e8e",
            "2fe5561598cd4b37846bcd6c74ecfe1f",
            "c4406929a61f41a99fa4353e6e7dc5f0",
            "08578a81f57e444cbe61361bc28f2b2a",
            "c6feec91e69949f295649e70f426fb70",
            "ff978122ddc64043a88ebbd413013e24",
            "af248e8d7ec0412ca0c965aa8f29e1cc"
          ]
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d41ef90950b249b4b81a76c2ac4d80c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'page_number': -41,\n",
              "  'page_char_count': 29,\n",
              "  'page_word_count': 4,\n",
              "  'page_sentence_count_raw': 1,\n",
              "  'page_token_count': 7.25,\n",
              "  'text': 'Human Nutrition: 2020 Edition'},\n",
              " {'page_number': -40,\n",
              "  'page_char_count': 0,\n",
              "  'page_word_count': 1,\n",
              "  'page_sentence_count_raw': 1,\n",
              "  'page_token_count': 0.0,\n",
              "  'text': ''}]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's get a random sample of the pages."
      ],
      "metadata": {
        "id": "8Qkxea2zgvoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.sample(pages_and_texts,k=3)"
      ],
      "metadata": {
        "id": "b5KuSo76gwI4",
        "outputId": "1fb02e26-b6f3-4c17-e6b9-964ff076e810",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'page_number': 317,\n",
              "  'page_char_count': 1035,\n",
              "  'page_word_count': 172,\n",
              "  'page_sentence_count_raw': 6,\n",
              "  'page_token_count': 258.75,\n",
              "  'text': '“Cholesterol  Chemical  Structure” by  Wesalius /  Public  Domain  Notably, the sterols found in plants resemble cholesterol in  structure. However, plant sterols inhibit cholesterol absorption in  the human body, which can contribute to lower cholesterol levels.  Although cholesterol is preceded by its infamous reputation, it is  clearly a vital substance in the body that poses a concern only when  there is excess accumulation of it in the blood. Like lecithin, the  body can synthesize cholesterol.  Figure 5.9 The Structure of Cholesterol  Learning Activities  Technology Note: The second edition of the Human  Nutrition Open Educational Resource (OER) textbook  features interactive learning activities.\\xa0 These activities are  available in the web-based textbook and not available in the  downloadable versions (EPUB, Digital PDF, Print_PDF, or  Open Document).  Learning activities may be used across various mobile  devices, however, for the best user experience it is strongly  Nonessential and Essential Fatty Acids  |  317'},\n",
              " {'page_number': 210,\n",
              "  'page_char_count': 1076,\n",
              "  'page_word_count': 201,\n",
              "  'page_sentence_count_raw': 7,\n",
              "  'page_token_count': 269.0,\n",
              "  'text': 'Beverage  Serving Size (oz) Kilocalories  Soda  12.0  124–189  Bottled sweet tea  12.0  129–143  Orange juice  12.0  157–168  Tomato/vegetable juice 12.0  80  Whole milk  12.0  220  Nonfat milk  12.0  125  Soy milk  12.0  147–191  Coffee, black  12.0  0–4  Coffee, with cream  12.0  39–43  Caffe latte, whole milk  12.0  200  Sports drink  12.0  94  Beer  12.0  153  White wine  5.0  122  Beverage Consumption in the United States  According to the Beverage Marketing Corporation, in the United  States in 2010 Americans consumed 29,325 millions of gallons of  refreshment beverages including soft drinks, coffee, tea, sports  drinks, energy drinks, fruit drinks, and bottled water.1  As in the past, carbonated soft drinks remained the largest  category of consumed beverages. In recent decades total caloric  1.\\xa0US Liquid Refreshment Beverage Market Increased by  1.2% in 2010, Beverage Marketing Corporation Reports.  Beverage Marketing Corporation.  http://www.beveragemarketing.com/?section=pressrel eases. Published 2010. Accessed March 17, 2011.  210  |  Water Concerns'},\n",
              " {'page_number': 867,\n",
              "  'page_char_count': 277,\n",
              "  'page_word_count': 59,\n",
              "  'page_sentence_count_raw': 1,\n",
              "  'page_token_count': 69.25,\n",
              "  'text': 'Image by  Brytni  K-aloha /  CC BY 4.0  Introduction  UNIVERSITY OF HAWAI‘I AT MĀNOA FOOD SCIENCE AND HUMAN  NUTRITION PROGRAM AND HUMAN NUTRITION PROGRAM  E mālama ‘ia nā pono o ka ‘āina e na ‘ōpio  The traditions of the land are perpetuated by its youth  Introduction  |  867'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Get some stats on the text**"
      ],
      "metadata": {
        "id": "m4aHMJB9iw3d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's perform a rough exploratory data analysis (EDA) to get an idea of the size of the texts (e.g. character counts, word counts etc) we're working with.\n",
        "\n",
        "The different sizes of texts will be a good indicator into how we should split our texts.\n",
        "\n",
        "Many embedding models have limits on the size of texts they can ingest, for example, the sentence-transformers model all-mpnet-base-v2 has an input size of 384 tokens.\n",
        "\n",
        "This means that the model has been trained in ingest and turn into embeddings texts with 384 tokens (1 token ~= 4 characters ~= 0.75 words).\n",
        "\n",
        "Texts over 384 tokens which are encoded by this model will be auotmatically reduced to 384 tokens in length, potentially losing some information.\n",
        "\n",
        "We'll discuss this more in the embedding section.\n",
        "\n",
        "For now, let's turn our list of dictionaries into a DataFrame and explore it."
      ],
      "metadata": {
        "id": "5mEjkZwTneKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(pages_and_texts)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ZXDf_3lanG0l",
        "outputId": "ab32ef9b-3727-4da6-b5c4-327175aee0f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
              "0          -41               29                4                        1   \n",
              "1          -40                0                1                        1   \n",
              "2          -39              320               54                        1   \n",
              "3          -38              212               32                        1   \n",
              "4          -37              797              145                        2   \n",
              "\n",
              "   page_token_count                                               text  \n",
              "0              7.25                      Human Nutrition: 2020 Edition  \n",
              "1              0.00                                                     \n",
              "2             80.00  Human Nutrition: 2020  Edition  UNIVERSITY OF ...  \n",
              "3             53.00  Human Nutrition: 2020 Edition by University of...  \n",
              "4            199.25  Contents  Preface  University of Hawai‘i at Mā...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7fc22988-35cc-44b6-b807-043b265a7aa3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_number</th>\n",
              "      <th>page_char_count</th>\n",
              "      <th>page_word_count</th>\n",
              "      <th>page_sentence_count_raw</th>\n",
              "      <th>page_token_count</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-41</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>7.25</td>\n",
              "      <td>Human Nutrition: 2020 Edition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-40</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-39</td>\n",
              "      <td>320</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>80.00</td>\n",
              "      <td>Human Nutrition: 2020  Edition  UNIVERSITY OF ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-38</td>\n",
              "      <td>212</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>53.00</td>\n",
              "      <td>Human Nutrition: 2020 Edition by University of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-37</td>\n",
              "      <td>797</td>\n",
              "      <td>145</td>\n",
              "      <td>2</td>\n",
              "      <td>199.25</td>\n",
              "      <td>Contents  Preface  University of Hawai‘i at Mā...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fc22988-35cc-44b6-b807-043b265a7aa3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7fc22988-35cc-44b6-b807-043b265a7aa3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7fc22988-35cc-44b6-b807-043b265a7aa3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f01c3939-8b08-4727-b09a-fd3401967529\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f01c3939-8b08-4727-b09a-fd3401967529')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f01c3939-8b08-4727-b09a-fd3401967529 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1208,\n  \"fields\": [\n    {\n      \"column\": \"page_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 348,\n        \"min\": -41,\n        \"max\": 1166,\n        \"num_unique_values\": 1208,\n        \"samples\": [\n          60,\n          713,\n          267\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_char_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 560,\n        \"min\": 0,\n        \"max\": 2308,\n        \"num_unique_values\": 883,\n        \"samples\": [\n          1742,\n          1077,\n          1003\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 95,\n        \"min\": 1,\n        \"max\": 429,\n        \"num_unique_values\": 349,\n        \"samples\": [\n          352,\n          78,\n          88\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_sentence_count_raw\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 1,\n        \"max\": 32,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          28,\n          24,\n          22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_token_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 140.09556874248855,\n        \"min\": 0.0,\n        \"max\": 577.0,\n        \"num_unique_values\": 883,\n        \"samples\": [\n          435.5,\n          269.25,\n          250.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1180,\n        \"samples\": [\n          \"Electrolytes Important for  Fluid Balance  UNIVERSITY OF HAWAI\\u2018I AT M\\u0100NOA FOOD SCIENCE AND HUMAN  NUTRITION PROGRAM AND HUMAN NUTRITION PROGRAM  Cells are about 75 percent water and blood plasma is about 95  percent water. Why then, does the water not flow from blood  plasma to cells? The force of water also known as hydrostatic  pressure  maintains  the  volumes  of  water  between  fluid  compartments against the force of all dissolved substances. The  concentration is the amount of particles in a set volume of water.  (Recall that individual solutes can differ in concentration between  the intracellular and extracellular fluids, but the total concentration  of all dissolved substances is equal.)  The force driving the water movement through the selectively  permeable membrane is the higher solute concentration on the  one side. Solutes at different concentrations on either side of a  selectively permeable membrane exert a force, called osmotic  pressure. The higher concentration of solutes on one side compared  to the other of the U-tube exerts osmotic pressure, pulling the  water to a higher volume on the side of the U-tube containing  more dissolved particles. When the osmotic pressure is equal to the  pressure of the water on the selectively permeable membrane, net  water movement stops (though it still diffuses back and forth at an  equal rate).  One equation exemplifying equal concentrations but different  volumes is the following  5 grams of glucose in 1 liter = 10 grams of glucose in 2 liters (5g/L =  5g/L)  The differences in concentrations of particular substances  provide concentration gradients that cells can use to perform work.  A concentration gradient is a form of potential energy, like water  172  |  Electrolytes Important for Fluid Balance\",\n          \"Units of Measure  UNIVERSITY OF HAWAI\\u2018I AT M\\u0100NOA FOOD SCIENCE AND HUMAN  NUTRITION PROGRAM AND HUMAN NUTRITION PROGRAM  In  nutrition,  there  are  two  systems  of  commonly  used  measurements: Metric and US Customary. We need both because  the US won\\u2019t adopt the metric system completely.  The Metric and US Customary System  These are commonly used prefixes for the Metric System:  Micro- (\\u03bc) 1/1,000,000th (one millionth)  Milli- (m)  1/1000th (one thousandth)  Centi- (c)  1/100th (one hundredth)  Deci- (d)  1/10th (one tenth)  Kilo- (k)  1000x (one thousand times)  Mass  Metric System  US Customary System Conversions  Microgram (\\u03bcg) Ounce (oz)  1 oz = 28.35 g  Milligram (mg)  Pound (lb)  1 lb = 16 oz  Gram (g)  1 lb = 454 g  Kilogram (kg)  1 kg = 2.2 lbs  18  |  Units of Measure\",\n          \"activity level. For example, dental problems can lead to difficulties  with chewing and swallowing, which in turn can make it hard to  maintain a healthy diet. The use of dentures or the preparation of  pureed or chopped foods can help solve this problem. There also  is a decreased thirst response in the elderly, and the kidneys have  a decreased ability to concentrate urine, both of which can lead to  dehydration.  Sensory Issues  At about age sixty, taste buds begin to decrease in size and number.  As a result, the taste threshold is higher in older adults, meaning  that more of the same flavor must be present to detect the taste.  Many elderly people lose the ability to distinguish between salty,  sour, sweet, and bitter flavors. This can make food seem less  appealing and decrease the appetite. An intake of foods high in  sugar and sodium can increase due to an inability to discern those  tastes. The sense of smell also decreases, which impacts attitudes  toward food. Sensory issues may also affect the digestion because  the taste and smell of food stimulates the secretion of  digestive\\u00a0enzymes in the mouth, stomach, and pancreas.  Dysphagia  Some older adults have difficulty getting adequate nutrition  because of the disorder dysphagia, which impairs the ability to  swallow. Any damage to the parts of the brain that control  swallowing can result in dysphagia, therefore stroke is a common  cause. Dysphagia is also associated with advanced dementia  because of overall brain function impairment. To assist older adults  suffering from dysphagia, it can be helpful to alter food consistency.  Older Adulthood: The Golden Years  |  923\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d41ef90950b249b4b81a76c2ac4d80c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_692c600764514cfeb3aae1209197cc28",
              "IPY_MODEL_158a0b121a63462ba8831bd583e8c36d",
              "IPY_MODEL_34dec64fd23642e2aceb15c647bccbe3"
            ],
            "layout": "IPY_MODEL_86a37dd502ab461daa16393a39e11e8e"
          }
        },
        "692c600764514cfeb3aae1209197cc28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fe5561598cd4b37846bcd6c74ecfe1f",
            "placeholder": "​",
            "style": "IPY_MODEL_c4406929a61f41a99fa4353e6e7dc5f0",
            "value": ""
          }
        },
        "158a0b121a63462ba8831bd583e8c36d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08578a81f57e444cbe61361bc28f2b2a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6feec91e69949f295649e70f426fb70",
            "value": 1
          }
        },
        "34dec64fd23642e2aceb15c647bccbe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff978122ddc64043a88ebbd413013e24",
            "placeholder": "​",
            "style": "IPY_MODEL_af248e8d7ec0412ca0c965aa8f29e1cc",
            "value": " 1208/? [00:01&lt;00:00, 622.31it/s]"
          }
        },
        "86a37dd502ab461daa16393a39e11e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fe5561598cd4b37846bcd6c74ecfe1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4406929a61f41a99fa4353e6e7dc5f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08578a81f57e444cbe61361bc28f2b2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c6feec91e69949f295649e70f426fb70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff978122ddc64043a88ebbd413013e24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af248e8d7ec0412ca0c965aa8f29e1cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}